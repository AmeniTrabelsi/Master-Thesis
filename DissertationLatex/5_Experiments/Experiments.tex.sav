\chapter{Experimental results}
\section{Context Dependent Spectral Unmixing}
In this section, we present the results of the proposed CDSU algorithm on synthetic and real data sets. We also provide a comparison to the results of the P-COMMEND algorithm. The parameters of both algorithms were tuned for better results. Future work will investigate proper choices of the parameters. The machine used for these experiments is equipped with a 3.6 GHz Intel Xeon processor and 24 GB RAM.
\subsection{Synthetic data sets}
In this subsection, we present the results of our proposed approach on the three toy data sets of section \ref{motivation}. We then apply our method to simulated hyperspectral data. Due to the simplicity of the toy data sets, the performance of the algorithms is evaluated visually. However, for the simulated data set, the performance is evaluated quantitatively.
%\subsubsection{Example 1}

First, we use the same 2-dimensional data set as in section \ref{Example1Motiv} (displayed in figure \ref{figExp1}(\subref{dataExp1})). The result of the CDSU algorithm on this data set, using $C=1$, $M=3$, $m=2$, $\alpha=1$, and $\beta=0.01$ is shown in figure \ref{CDSUExp1}, where the detected endmembers are shown in red.
\begin{figure}[htb]
  \centering
  \includegraphics[width=0.49\linewidth]{Example1CDSU.png}
\caption{Result of the CDSU algorithm on a sample 2-D synthetic data with one convex hull.}
\label{CDSUExp1}
\end{figure}
As it can be seen, the CDSU algorithm succeeded in identifying endmembers at the vertices of the convex hull enclosing the data points providing a tight fit around them.
%\subsubsection{Example 2}

As a second example, we use the same 2-dimensional data set as in section \ref{Example2Motiv} (displayed in figure \ref{figExp2}(\subref{dataExp2})). The result of the CDSU algorithm on this data set, using $C=2$, $M=3$, $m=2$, $\alpha=20$, and $\boldsymbol\beta=[0.01, 0.01]$ (same as the value of $\alpha$ used for P-COMMEND) is shown in figure \ref{CDSUExp2}. The detected endmembers are shown in red for one cluster and in green for the other cluster.
\begin{figure}[htb]
  \centering
  \includegraphics[width=0.49\linewidth]{Example2CDSU.png}
  \caption{Result of the CDSU algorithm on a sample 2-D synthetic data with two convex hulls.}
  \label{CDSUExp2}
\end{figure}
As it can be seen, the CDSU algorithm succeeded in identifying endmember sets at the vertices of the convex hulls enclosing the data points and thus, providing a tight fit around them.
%\subsubsection{Example 3}

For a third example, we use the same 2-dimensional data set as in section \ref{Example3Motiv} (displayed in figure \ref{figExp3}(\subref{TrueAssigExp3})). The result of the CDSU algorithm on this data set, using $C=3$, $M=3$, $m=2$, $\alpha=50$, and $\boldsymbol\beta=[0.1, 0.1, 0.1]$ (same as the value of $\alpha$ used for P-COMMEND) is shown in figure \ref{CDSUExp3}. The same initializations of $\mathbf{U}$ and $\mathbf{E}_{i}$ as for P-COMMEND were used. The identified clusters are represented using different colors, and the endmembers for each cluster are represented using bolder points.
\begin{figure}[htb]
  \centering
  \includegraphics[width=0.49\linewidth]{Example3CDSU.png}
  \caption{Result of the CDSU algorithm on a sample 2-D synthetic data with three convex hulls.}
  \label{CDSUExp3}
\end{figure}
As it can be seen, the CDSU algorithm succeeded in identifying endmember sets at the vertices of the convex hulls enclosing the data points, providing a tight fit around them. It also provided clusters that match the distribution of the data.
%\subsubsection{Simulated hyperspectral data}

For a forth example, we consider a simulated hyperspectral data set. The data is generated using the convex geometry model in (\ref{convmodl}) with six endmember signatures, selected from the USGS (United States Geological Survey) digital spectral library \cite{75}. The spectral library contains spectra of 423 minerals, 17 plants and some miscellaneous materials. In our experiment, we use spectra of the minerals Spessartine, Halloysite, Chlorite, Rectorite, Lizardite and Kaolinite, shown in figure \ref{minerals}, to generate 1000 spectral signatures. The spectra have 224 spectral bands, spanning the 0.383 - 2.508 $\mu m$ wavelength range.
%Sodium Bicarbonate, Gypsum, Chlorite, Quartz, Limonite and Kaolinite,
\begin{figure}[htb]
  \centering
  \includegraphics[width=1\linewidth]{minerals.png}
  \caption{USGS spectra used to generate the simulated data}
  \label{minerals}
\end{figure}
Each simulated hyperspectral pixel is a convex combination of three of the endmembers, resulting in two convex regions. The proportions for each data point are generated by sampling from a standard uniform distribution and are normalized to sum to one. The first three endmembers are used to generate the first convex region, and the last three endmembers are used to generate the second one, each having 500 points. Zero-mean Gaussian noise is added to the simulated spectra at three noise levels. The noise levels are adjusted by changing the variance of the Gaussian to obtain Signal to Noise Ratios (SNR) of 20 dB, 30 dB and 50 dB  for the three levels. The SNR is defined using the logarithmic decibel scale as:
\begin{equation}\label{SNR}
    SNR=10\log_{10}\left(\frac{P_{data}}{P_{noise}}\right),
\end{equation}
where $P_{data}$ is the average power of the data, and $P_{noise}$ is the average power of the noise.
\\To evaluate the performance of the CDSU algorithm and compare it to P-COMMEND, the abundance fractions and the endmember estimates are compared with the true ones. Based on the mean square error (MSE), we define the spectral mean error ($SME$) and the abundance mean error ($AME$) as
\begin{equation}\label{SME}
    SME\equiv\frac{1}{Md}\|\mathbf{E}-\mathbf{\hat{E}}\|_{F}^{2},
\end{equation}
and
\begin{equation}\label{AME}
    AME\equiv\frac{1}{MN}\|\mathbf{P}-\mathbf{\hat{P}}\|_{F}^{2}.
\end{equation}
In (\ref{SME}) and (\ref{AME}), $M$ is the total number of endmembers, $d$ is the number of spectral bands, and $N$ is the number of data points. The rows of $\mathbf{E}$ and $\mathbf{\hat{E}}$ represent the true endmembers and the endmember estimates respectively. $\mathbf{P}$ is a $N \times M$ matrix representing the true endmember abundance fractions. $\mathbf{\hat{P}}$ is a $N \times M$ matrix representing the endmember abundance fraction estimates, where each proportion value is multiplied by the corresponding cluster membership. The notation $\|.\|_{F}$ stands for the Frobenius norm.
\\Another common performance metric is the spectral angle distance, which measures the angle between a signature $\mathbf{e}_{i}$ and its estimate $\mathbf{\hat{e}}_{i}$ \cite{1}. Based on this metric, we define a spectral mean angle error ($SMAE$) as
\begin{equation}\label{SMAE}
    SMAE\equiv\sqrt{\frac{1}{M}\sum\limits_{i=1}^{M}\left[\arccos\left(\frac{\mathbf{e}_{i}\mathbf{\hat{e}}_{i}^{T}}{\|\mathbf{e}_{i}\|\|\mathbf{\hat{e}}_{i}\|}\right)\right]^{2}}.
\end{equation}
It is clear that the performance of the algorithms increases as $SME$, $AME$, and $SMAE$ approach zero. Notice, however, that the estimates of $\mathbf{E}$ and $\mathbf{P}$  are up to a permutation matrix. Thus, a simple algorithm based on the Hungarian method \cite{76} has been designed to infer the permutation matrix.
\\We run the CDSU and P-COMMEND algorithms using the parameters in table \ref{Paramtable}.
\small
\begin{table}[htb]
\caption{Parameters used for the CDSU and P-COMMEND algorithms on the USGS simulated hyperspectral data}
\centering
\scalebox{0.72}{
\begin{tabular}{|c|c|c|}
   \hline
   % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
   Parameters & CDSU & P-COMMEND \\\hline
   $C$ & 2 & 2 \\\hline
   $M$ & 3 & 3 \\\hline
   $m$ & 1.25 & 1.25 \\\hline
   $\alpha$, $\boldsymbol\beta$& $\alpha=200$, $\boldsymbol\beta=[0.1, 0.1]$  & $\alpha=0.1$ \\\hline
   \begin{tabular}[c]{@{}c@{}}Stopping criterion\\($Iter$ = Iteration number)\end{tabular}& $abs\left(\frac{J_{CDSU}(Iter+1)-J_{CDSU}(Iter)}{J_{CDSU}(Iter+1)}\right)<10^{-6}$&$abs\left(\frac{J_{PCOMMEND}(Iter+1)-J_{PCOMMEND}(Iter)}{J_{PCOMMEND}(Iter+1)}\right)<10^{-6}$\\\hline
 \end{tabular}
 }
\label{Paramtable}
\end{table}
\normalsize
 %$C=2$, $M=3$, $m=1.25$, $\alpha=200$, $\boldsymbol\beta=[0.1, 0.1]$ and a threshold $thresh=0.001$ for the stopping condition. Similarly, we run the P-COMMEND algorithm using $C=2$, $M=3$, $m=1.25$, $\alpha=0.1$, and a threshold $thresh=0.001$ for the stopping condition.
We run each algorithm 25 times at each noise level. For each run, we use the FCM \cite{69} and MVSA \cite{67} algorithms for the initialization of the memberships, centers and endmembers. This experiment is designed to test the sensitivity of CDSU to noise and initialization, and to provide a comparison to P-COMMEND.
%\\Table \ref{SMEtable} shows the mean and standard deviation of the endmember estimation error of both algorithms, across the 25 runs and at all noise levels, using the spectral mean error ($SME$).
%\small
%\begin{table}[htb]
%\caption{Mean and standard deviation (in brackets) of the spectral mean error ($SME$) of CDSU and P-COMMEND on the USGS simulated hyperspectral data, based on 25 runs with increasing noise and random initialization}
%\centering
%\scalebox{1}{
%\begin{tabular}{|c|c|c|}
%  \hline
%  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
%  SNR (dB) & CDSU & P-COMMEND \\\hline
%  50 & 7.3515e-004 (2.6631e-006) & 7.3072e-004 (1.3855e-006) \\\hline
%  30 &  7.5163e-004 (1.9945e-005) & 7.3564e-004 (1.6625e-005) \\\hline
%  20 &  8.5167e-004 (9.2673e-005) & 0.0013 (9.0451e-005) \\\hline
%\end{tabular}
%}
%\label{SMEtable}
%\end{table}
%\normalsize
%\\Table \ref{SMAEtable} shows the mean and standard deviation of the endmember estimation error of both algorithms, across the 25 runs and at all noise levels, using the spectral mean angle error ($SMAE$).
%\small
%\begin{table}[htb]
%\caption{Mean and standard deviation (in brackets) of the spectral mean angle error ($SMAE$) of CDSU and P-COMMEND on the USGS simulated hyperspectral data, based on 25 runs with increasing noise and random initialization}
%\centering
%\scalebox{1}{
%\begin{tabular}{|c|c|c|}
%  \hline
%  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
%  SNR (dB)& CDSU & P-COMMEND \\\hline
%  50 &  1.4049 (1.2063e-006) & 1.4049 (6.8544e-007) \\\hline
%  30 &   1.4049 (3.0583e-006) &  1.4049 (3.0746e-006) \\\hline
%  20 & 1.4050 (2.4777e-005) & 1.4050 (8.1935e-006) \\ \hline
%\end{tabular}
%}
%\label{SMAEtable}
%\end{table}
%\normalsize
%\\Table \ref{AMEtable} shows the mean and standard deviation of the abundances estimation error of both algorithms, across the 25 runs and at all noise levels, using the abundance mean error ($AME$).
%\small
%\begin{table}[htb]
%\caption{Mean and standard deviation (in brackets) of the abundance mean error ($AME$) of CDSU and P-COMMEND on the USGS simulated hyperspectral data, based on 25 runs with increasing noise and random initialization}
%\centering
%\scalebox{1}{
%\begin{tabular}{|c|c|c|}
%  \hline
%  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
%  SNR (dB)& CDSU & P-COMMEND \\\hline
%  50 &  9.0281e-004 (1.2176e-005) & 8.9104e-004 (4.6020e-006) \\\hline
%  30 &  9.8207e-004 (4.9887e-005) & 9.3822e-004 (3.6299e-005) \\\hline
%  20 & 0.0023 (5.2168e-004) &  0.0059 (5.5725e-004) \\ \hline
%\end{tabular}
%}
%\label{AMEtable}
%\end{table}
%\normalsize
\\Figures \ref{ErrorMetrics}(\subref{ErrorSME}), (\subref{ErrorSMAE}) and (\subref{ErrorAME}) show a box plot of the different error metrics of both CDSU and P-COMMEND algorithms across the 25 runs and at all noise levels. On each box, the central red mark represents the median value, the edges of the box are the $25^{\text{th}}$ and $75^{\text{th}}$ percentiles, the whiskers extend to the most extreme values not considered outliers, and outliers are plotted individually using red crosses. An outlier is a value smaller than the first quartile minus 1.5 times the interquartile range (third minus first quartile), or higher than the third quartile plus 1.5 times the interquartile range.
\begin{figure}[h!]
\begin{subfigure}[b]{0.49\linewidth}
  \centering
  \includegraphics[width=1\linewidth]{BoxplotSMESimulated.png}
\caption{}
\label{ErrorSME}
\end{subfigure}
\begin{subfigure}[b]{0.49\linewidth}
  \centering
  \includegraphics[width=1\linewidth]{BoxplotSMAESimulated.png}
\caption{}
\label{ErrorSMAE}
\end{subfigure}

\centering
\begin{subfigure}[b]{0.49\linewidth}
  \centering
  \includegraphics[width=1\linewidth]{BoxplotAMESimulated.png}
\caption{}
\label{ErrorAME}
\end{subfigure}
\caption{Error metrics for CDSU and P-COMMEND on the USGS simulated data across the 25 runs and at all noise levels: (a) $SME$, (b) $SMAE$, (c) $AME$.}
\label{ErrorMetrics}
\end{figure}
%\\Examining these results, we see that the standard deviation of all error metrics across the 25 runs are very small, meaning that both algorithms are not sensitive to initialization, leading every time to consistent results. Also, we see that the error increases for both algorithms as the noise level increases, which is expected. Furthermore, the CDSU algorithm outperforms the P-COMMEND algorithm and this becomes more significant as the noise level increases. An explanation for this would be that CDSU is more robust to noise than P-COMMEND due to the clustering term in its objective function. Noise would not affect clustering as much as it would affect spectral unmixing.
\\Examining these results, we can see that CDSU and P-COMMEND perform similarly in low noise level cases (SNR = 30 and 50 dB). Both algorithms are also robust to initialization. For the high noise level case (SNR = 20 dB), CDSU clearly outperforms P-COMMEND ($p-value=1.4e-009$ using the Wilcoxon rank sum test). An explanation for this would be that CDSU is more robust to noise than P-COMMEND due to the clustering term in its objective function. Noise would not affect clustering as much as it would affect spectral unmixing. Furthermore, we see that the error metric increases for both algorithms as the noise level increases, which is expected.
\\To compare and illustrate the results further, we visualize the estimated endmembers by both algorithms for the case of the highest noise level (SNR = 20 dB). We pick the run in which P-COMMEND gave the highest error.
Figure \ref{TESNR20}(\subref{TESNR20CDSU}) shows the true (solid lines) and estimated (dashed lines) endmembers resulting from the CDSU algorithm. Similarly, figure \ref{TESNR20}(\subref{TESNR20PCOMMEND}) shows the true and estimated endmembers resulting from the P-COMMEND algorithm. We can see that CDSU resulted in better estimates of the endmembers.
\begin{figure}[!h]
\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{TrueEstimatedESNR20CDSU.png}
\caption{}
\label{TESNR20CDSU}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{TrueEstimatedESNR20PCOMMEND.png}
\caption{}
\label{TESNR20PCOMMEND}
\end{subfigure}
\caption{True (solid lines) and estimated (dashed lines) endmembers for the USGS simulated data with SNR = 20 dB using (a) CDSU and (b) P-COMMEND.}
\label{TESNR20}
\end{figure}
\\To analyze the results further, we check the composition of the clusters generated by P-COMMEND and CDSU. The cluster assignment is based on the highest membership values. We can see, as shown in table \ref{compostable}, that both algorithms succeeded in generating clusters that are pure and that correspond to the two original convex regions.
\small
\begin{table}[htb]
\caption{Composition of the clusters generated by CDSU and P-COMMEND on the USGS simulated data}
\centering
\scalebox{1}{
\begin{tabular}{|c|c|c|}
  \hline
  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
  & Convex set 1 & Convex set 2 \\\hline
  Cluster 1 &    500 & 0 \\\hline
  Cluster 2 &   0 & 500 \\\hline
\end{tabular}
}
\label{compostable}
\end{table}
\normalsize
\\We take the analysis one step further and we look at the membership values of the data points in each cluster. To do this, we perform a scatter plot of the two first principal components of the data and we color each point with a shade corresponding to its membership value in a specific cluster. Figures \ref{membercl1}(\subref{membercl1CDSU}) and (\subref{membercl1PCOMMEND}) show the membership values in cluster 1 generated by P-COMMEND and CDSU. Similarly, figures \ref{membercl2}(\subref{membercl2CDSU}) and (\subref{membercl2PCOMMEND}) show the membership values in cluster 2. We can see a difference in the membership values assigned by each algorithm. Compared to CDSU, P-COMMEND assigned higher membership values in cluster 1 to some points from cluster 2 (light blue shades in figure \ref{membercl2}(\subref{membercl1PCOMMEND})). And due to the sum to one constraint on the memberships, the same points were assigned lower membership values, compared to CDSU, in cluster 2 that they belong to (light green shades in figure \ref{membercl2}(\subref{membercl2PCOMMEND})). These values interfere in the update equations of the endmembers and abundances, which leads to worse estimates for P-COMMEND, and better estimates for CDSU.
\begin{figure}[!h]
\begin{subfigure}[b]{0.49\linewidth}
  \centering
  \includegraphics[width=1\linewidth]{membershipscluster1CDSU.png}
\caption{}
\label{membercl1CDSU}
\end{subfigure}
\begin{subfigure}[b]{0.49\linewidth}
  \centering
  \includegraphics[width=1\linewidth]{membershipscluster1PCOMMEND.png}
\caption{}
\label{membercl1PCOMMEND}
\end{subfigure}
\caption{Membership values in cluster 1 for the USGS simulated data with SNR = 20 dB using (a) CDSU and (b) P-COMMEND. Two principal components of the data are scatter plotted.}
\label{membercl1}
\end{figure}
\begin{figure}[!h]
\begin{subfigure}[b]{0.49\linewidth}
  \centering
  \includegraphics[width=1\linewidth]{membershipscluster2CDSU.png}
\caption{}
\label{membercl2CDSU}
\end{subfigure}
\begin{subfigure}[b]{0.49\linewidth}
  \centering
  \includegraphics[width=1\linewidth]{membershipscluster2PCOMMEND.png}
\caption{}
\label{membercl2PCOMMEND}
\end{subfigure}
\caption{Membership values in cluster 2 for the USGS simulated data with SNR = 20 dB using (a) CDSU and (b) P-COMMEND. Two principal components of the data are scatter plotted.}
\label{membercl2}
\end{figure}
\\We bring back the update equations of the memberships of P-COMMEND and CDSU to understand this difference. The update equation of the memberships for P-COMMEND is:
\begin{eqnarray}\label{uPcmd2}
   u_{ij}=\frac{\left[\frac{1}{(\mathbf{x}_{j}-\mathbf{p}_{ij}\mathbf{E}_{i})(\mathbf{x}_{j}-\mathbf{p}_{ij}\mathbf{E}_{i})^{T}}\right]^{\frac{1}{m-1}}}
   {\sum\limits_{q=1}^{C}\left[\frac{1}{(\mathbf{x}_{j}-\mathbf{p}_{qj}\mathbf{E}_{q})(\mathbf{x}_{j}-\mathbf{p}_{qj}\mathbf{E}_{q})^{T}}\right]^{\frac{1}{m-1}}}.
\end{eqnarray}
And the update equation of the memberships for CDSU, in (\ref{u}), can be rewritten as:
\begin{equation}\label{u2}
   u_{ij}=
\frac{\left[\frac{1}{(\mathbf{x}_{j}-\mathbf{c}_{i})(\mathbf{x}_{j}-\mathbf{c}_{i})^{T}+\alpha (\mathbf{x}_{j}-\mathbf{p}_{ij}\mathbf{E}_{i})(\mathbf{x}_{j}-\mathbf{p}_{ij}\mathbf{E}_{i})^{T}}\right]^{\frac{1}{m-1}}}{\sum\limits_{q=1}^{C}\left[\frac{1}{(\mathbf{x}_{j}-\mathbf{c}_{q})(\mathbf{x}_{j}-\mathbf{c}_{q})^{T}+\alpha (\mathbf{x}_{j}-\mathbf{p}_{qj}\mathbf{E}_{q})(\mathbf{x}_{j}-\mathbf{p}_{qj}\mathbf{E}_{q})^{T}}\right]^{\frac{1}{m-1}}}.
\end{equation}
%We can see that the memberships assigned by CDSU to points from cluster $k$, in clusters $i\neq k$, are smaller than the ones assigned by P-COMMEND due to the term $(\mathbf{x}_{j}-\mathbf{c}_{i})(\mathbf{x}_{j}-\mathbf{c}_{i})^{T}$ which is high since $\mathbf{x}_{j}$ is from cluster $k$.
By examining (\ref{u2}), we notice that a pixel $j$ will have a high membership in cluster $i$ if its spectra is close to the centroid, $\mathbf{c}_{i}$, of that cluster in the feature space, and it fits the model of that cluster. This is unlike the update equation of the memberships for P-COMMEND in (\ref{uPcmd2}), where a pixel $j$ will have a high membership in model $i$ only if it fits that model, regardless of the spectral distribution around it. This shows the importance of the clustering term in taking the distribution of the data into account and thus leading to better endmember and abundance estimates. This would affect any further analysis or processing based on the estimated endmembers or abundances.
%\\To analyze the results further, we plot the spectral signatures of the clusters generated by the P-COMMEND and CDSU algorithms, labeling each point of them with the convex set it originally came from. Figures \ref{signclustsimulPCOMMEND}(\subref{signclust1simulPCOMMEND}) and (\subref{signclust2simulPCOMMEND}) show these signatures for P-COMMEND, and figures \ref{signclustsimulCDSU}(\subref{signclust1simulCDSU}) and (\subref{signclust2simulCDSU}) show them for CDSU.
%\begin{figure}[htb]
%\begin{subfigure}[b]{1\linewidth}
%  \centering
%  \includegraphics[width=1\linewidth]{cluster1PCOMMENDSimulated.png}
%  \caption{}
%  \label{signclust1simulPCOMMEND}
%\end{subfigure}
%
%\begin{subfigure}[b]{1\linewidth}
%  \centering
%  \includegraphics[width=1\linewidth]{cluster2PCOMMENDSimulated.png}
%  \caption{}
%  \label{signclust2simulPCOMMEND}
%\end{subfigure}
%\caption{Spectral signatures of the clusters generated by the P-COMMEND algorithm on the USGS simulated data: (a) Cluster 1  (b) Cluster 2.}
%\label{signclustsimulPCOMMEND}
%\end{figure}
%\begin{figure}[htb]
%\begin{subfigure}[b]{1\linewidth}
%  \centering
%  \includegraphics[width=1\linewidth]{cluster1CDSUSimulated.png}
%  \caption{}
%  \label{signclust1simulCDSU}
%\end{subfigure}
%
%\begin{subfigure}[b]{1\linewidth}
%  \centering
%  \includegraphics[width=1\linewidth]{cluster2CDSUSimulated.png}
%  \caption{}
%  \label{signclust2simulCDSU}
%\end{subfigure}
%\caption{Spectral signatures of the clusters generated by the CDSU algorithm on the USGS simulated data with SNR = 20 dB: (a) Cluster 1  (b) Cluster 2.}
%\label{signclustsimulCDSU}
%\end{figure}
%We can see that the clusters resulting from P-COMMEND are a mixture of points generated from both sets of endmembers. This mixture explains the erroneous estimates of the endmembers and abundances. However, the points of each cluster resulting from CDSU are purely generated from a separate endmember set.
%Hence, CDSU generated better clusters that took into account the spectral distribution. Clusters are more meaningful and match the distribution of the generated data. This is due to the clustering term in the objective function of CDSU.

To compare the time complexity of CDSU and P-COMMEND, we generate a box plot of the running time, expressed in seconds, across the 25 runs and at all noise levels. Both algorithms were ran using MATLAB R2011a. Figure \ref{TimeBox} shows this box plot.
\begin{figure}[!h]
  \centering
  \includegraphics[width=0.49\linewidth]{BoxplotTimeSimulated.png}
\caption{Running time (in seconds) of CDSU and P-COMMEND on the USGS simulated data across the 25 runs and at all noise levels.}
\label{TimeBox}
\end{figure}
%\small
%\begin{table}[htb]
%\caption{Mean and standard deviation (in brackets) of the running time (in seconds) of CDSU and P-COMMEND on the USGS simulated hyperspectral data with SNR = 20 dB, based on 25 runs with increasing noise and random initialization}
%\centering
%\scalebox{1}{
%\begin{tabular}{|c|c|c|}
%  \hline
%  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
%  SNR (dB)& CDSU & P-COMMEND \\\hline
%  50 &    8.7558 (2.4633) & 6.7098 (1.6729) \\\hline
%  30 &   5.1875 (0.8276) & 4.4443 (0.9310) \\\hline
%  20 & 5.2316 (0.8026) & 5.9955 (0.5544) \\\hline
%\end{tabular}
%}
%\label{timetable}
%\end{table}
%\normalsize
%First, we notice that the running time decreases as the noise level increases for both algorithms. This is due to the fact that a noisy data requires less iterations and thus, less time to convergence than a cleaner one. Second,
We notice that the CDSU algorithm takes a longer time to run compared to P-COMMEND for the cases where SNR = 30 or 50 dB. The reason for this is that CDSU requires more computations than P-COMMEND. For the SNR = 20 dB case, we see that CDSU becomes slightly faster than P-COMMEND. This can be explained by the clustering term in CDSU which makes it more robust to noise and thus requiring less time to converge.
 %Second, in general, it takes CDSU more iterations than P-COMMEND to converge.
%\\Table \ref{iterationstable} shows the mean and standard deviation of the number of iterations needed by both algorithms to converge, across the 25 runs and at all noise levels. We can see that CDSU requires more iterations to converge than P-COMMEND. Also, this number increases as the noise level increases.
%\small
%\begin{table}[htb]
%\caption{Mean and standard deviation (in brackets) of the number of iterations needed by CDSU and P-COMMEND to converge on the USGS simulated hyperspectral data, based on 25 runs with increasing noise and random initialization}
%\centering
%\scalebox{1}{
%\begin{tabular}{|c|c|c|}
%  \hline
%  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
%  SNR (dB)& CDSU & P-COMMEND \\\hline
%  50 &  263.1600 (62.0857) &  319.8800 (81.9076) \\\hline
%  30 &  164 (27.2381) &   218.8400 (47.5085) \\\hline
%  20 &  163.1200 (24.5973) &  290.1600 (26.0171) \\  \hline
%\end{tabular}
%}
%\label{iterationstable}
%\end{table}
%\normalsize

We use the simulated data set, with SNR = 20 dB, to illustrate another advantage of our proposed approach. One might argue and say why not cluster the data into whatever number of endmember sets we are trying to find and then use a single convex region unmixing algorithm, ICE for instance, to find the endmembers and abundances for each cluster. Well, the response is that we are interested in simultaneously unmixing while taking into account the distribution of the data. This may lead to different results than if we cluster first and then unmix.
\\Figures \ref{signclust1simulFCM} and \ref{signclust2simulFCM} show the result of applying the FCM clustering algorithm to the simulated data with SNR = 20 dB. We plot the spectral signatures of the two resulting clusters, labeling each point of them with the convex set it originally came from. We clearly see that the resulting clusters include a mixture of points originally generated from both endmember sets, and hence, any unmixing algorithm applied to each cluster would result in erroneous endmember estimates. It is to note here that even if we initialize FCM with the true cluster assignments, it converges to the same result of figure \ref{signclustsimulFCM}.
\\On the other hand, CDSU resulted in pure clusters (figure \ref{signclustsimulCDSU}), even though it started with the very same erroneous FCM partition as an initialization, and hence its estimates are definitely better.
\begin{figure}[!htb]
\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{cluster1FCMSimulated.png}
  \caption{}
  \label{signclust1simulFCM}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{cluster2FCMSimulated.png}
  \caption{}
  \label{signclust2simulFCM}
\end{subfigure}
\caption{Spectral signatures of the clusters generated by the FCM algorithm on the USGS simulated data with SNR = 20 dB: (a) Cluster 1  (b) Cluster 2.}
\label{signclustsimulFCM}
\end{figure}
\begin{figure}[!htb]
\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{cluster1CDSUSimulated.png}
  \caption{}
  \label{signclust1simulCDSU}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{cluster2CDSUSimulated.png}
  \caption{}
  \label{signclust2simulCDSU}
\end{subfigure}
\caption{Spectral signatures of the clusters generated by the CDSU algorithm on the USGS simulated data with SNR = 20 dB: (a) Cluster 1  (b) Cluster 2.}
\label{signclustsimulCDSU}
\end{figure}
\\In order to understand why FCM leads to mixed clusters whereas CDSU succeeds to return pure ones, we take a closer look at the objective function values of both algorithms as they run. Figure \ref{FCMInit} shows the evolution of the objective function of FCM until its convergence. We can see that it reaches a local minimum in few iterations.
\begin{figure}[htb]
  \centering
  \includegraphics[width=0.7\linewidth]{FCMObjInitialization.png}
\caption{Objective function of the FCM algorithm used for cluster initialization.}
\label{FCMInit}
\end{figure}
 As CDSU runs, we compute the objective function of FCM using the resulting memberships and centers from CDSU at every iteration. Figure \ref{FCMObjCDSU} shows the evolution of this objective function. We can see that, as CDSU runs, the objective function of FCM increases. This explains why FCM did not reach the optimal pure clusters. It is because the corresponding objective function's value is greater than the local minimum that FCM found during the initialization.
\begin{figure}[htb]
  \centering
  \includegraphics[width=0.7\linewidth]{FCMobjiterCDSU1.png}
\caption{Evolution of the FCM objective function as CDSU runs.}
\label{FCMObjCDSU}
\end{figure}
\\On the other hand, figure \ref{CDSUObjCDSU} shows the evolution of the objective function of the CDSU algorithm. We can see that it decreases until it reaches a local minimum. This can be explained by the second term of the objective function corresponding to the spectral unmixing. It is the one decreasing so much that it compensates for the increase of the first term corresponding to the clustering. And hence, the overall objective function decreases.
\begin{figure}[htb]
  \centering
  \includegraphics[width=0.7\linewidth]{CDSUobj.png}
\caption{Evolution of the CDSU objective function as CDSU runs.}
\label{CDSUObjCDSU}
\end{figure}
\\We pick few intermediary results during the run of the CDSU algorithm in order to illustrate the composition of the clusters at each iteration. The initial composition is the same as in the FCM result shown in figure \ref{signclustsimulFCM}. The composition of the clusters after the first iteration is shown in figure \ref{signclustsimulCDSUIter1}. We can see that CDSU succeeded in purifying cluster 2. It is now composed only of points generated from the second set of endmembers. Cluster 1 also got purer with only three points generated from the second set of endmembers.
\newpage
\vfill
\begin{figure}[!htb]
\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{CDSUIter1Cluster1spectralSign.png}
  \caption{}
  \label{signclust1simulCDSUIter1}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{CDSUIter1Cluster2spectralSign.png}
  \caption{}
  \label{signclust2simulCDSUIter1}
\end{subfigure}
\caption{Spectral signatures of the resulting clusters from the CDSU algorithm on the USGS simulated data with SNR = 20 dB after the first iteration: (a) Cluster 1  (b) Cluster 2.}
\label{signclustsimulCDSUIter1}
\end{figure}
\vfill
\clearpage
Figure \ref{signclustsimulCDSUIter2} shows the composition of the clusters after the second iteration. Cluster 2 is always pure, and cluster 1 now has two points only generated from the second set of endmembers.
\begin{figure}[!htb]
\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{CDSUIter2Cluster1spectralSign.png}
  \caption{}
  \label{signclust1simulCDSUIter2}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{CDSUIter2Cluster2spectralSign.png}
  \caption{}
  \label{signclust2simulCDSUIter2}
\end{subfigure}
\caption{Spectral signatures of the resulting clusters from the CDSU algorithm on the USGS simulated data with SNR = 20 dB after the second iteration: (a) Cluster 1  (b) Cluster 2.}
\label{signclustsimulCDSUIter2}
\end{figure}
\\Figure \ref{signclustsimulCDSUIter3} shows the composition of the clusters after the third iteration. Cluster 2 is always pure, and cluster 1 now has one point only generated from the second set of endmembers.
\begin{figure}[!htb]
\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{CDSUIter3Cluster1spectralSign.png}
  \caption{}
  \label{signclust1simulCDSUIter3}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{CDSUIter3Cluster2spectralSign.png}
  \caption{}
  \label{signclust2simulCDSUIter3}
\end{subfigure}
\caption{Spectral signatures of the resulting clusters from the CDSU algorithm on the USGS simulated data with SNR = 20 dB after the third iteration: (a) Cluster 1  (b) Cluster 2.}
\label{signclustsimulCDSUIter3}
\end{figure}
This result remains for six more iterations, and at the tenth iteration, both clusters get pure as shown in figure \ref{signclustsimulCDSU}. For the remaining of the iterations, the composition of the clusters do not change and the CDSU algorithm keeps updating the variables until convergence.

Using two dimensional toy data and simulated hyperspectral data, we were able to illustrate the effectiveness of the proposed CDSU algorithm in identifying correct abundances and endmember sets. We also showed that CDSU outperformed P-COMMEND in the case of noisy data. Furthermore, we showed the difference between our approach, that performs spectral unmixing while simultaneously taking into account the distribution of the data in the spectral space, and simply clustering the data and then unmixing each cluster separately. \\In the next section, we present the results of CDSU on real hyperspectral data and compare them to those of P-COMMEND.
\subsection{Real hyperspectral data}
In this section, we consider a real hyperspectral data set. The data was collected on July 8, 2002 over an urban area around the Pavia University in northern Italy, using the Reflective Optics System Imaging Spectrometer\footnote{Data available at http://www.ehu.es/ccwintco/index.php/Hyperspectral\_Remote\_Sensing\_Scenes} (ROSIS). The ROSIS sensor collects data over the $430-860$ nm wavelength range at a 4 nm spectral sampling interval. The image originally contains 610$\times$340 pixels having 103 spectral bands each ($430-838$ nm), with a spatial resolution of 1.3 meters. In our experiment, we used a down sampled version of the image, of size 305$\times$170. The scene consists of both natural and urban regions as shown in figure \ref{pavia}. Ground truth labels are provided for some areas of the scene. Nine classes are defined: asphalt, meadows, gravel, trees, painted metal sheets, bare soil, bitumen, self-blocking bricks and shadows. Figure \ref{GTPaviaU} shows the ground truth image of the Pavia University data set.
\begin{figure}[!h]
\centering
\includegraphics[width=0.45\linewidth, height=0.65\linewidth]{Pavia305170.png}
\caption{Image of the Pavia University data set (using bands 56, 29 and 12 to form R, G and B channels to create the color image)}
\label{pavia}
\end{figure}
\begin{figure}[!h]
\centering
\includegraphics[width=0.5\linewidth, height=0.65\linewidth]{PaviaGT305170.png}
\caption{Ground truth image of the Pavia University data set}
\label{GTPaviaU}
\end{figure}
\\We run the CDSU and P-COMMEND on this data set using the parameters in table \ref{Paramtable2}.
\small
\begin{table}[htb]
\caption{Parameters used for the CDSU and P-COMMEND algorithms on the Pavia University hyperspectral data}
\centering
\scalebox{0.75}{
\begin{tabular}{|c|c|c|}
   \hline
   % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
   Parameters & CDSU & P-COMMEND \\\hline
   $C$ & 3 & 3 \\\hline
   $M$ & 3 & 3 \\\hline
   $m$ & 1.25 & 1.25 \\\hline
   $\alpha$, $\boldsymbol\beta$& $\alpha=1$, $\boldsymbol\beta=[5, 5, 5]$  & $\alpha=5$ \\\hline
   \begin{tabular}[c]{@{}c@{}}Stopping criterion\\($Iter$ = Iteration number)\end{tabular} & $abs\left(\frac{J_{CDSU}(Iter+1)-J_{CDSU}(Iter)}{J_{CDSU}(Iter+1)}\right)<10^{-6}$&$abs\left(\frac{J_{PCOMMEND}(Iter+1)-J_{PCOMMEND}(Iter)}{J_{PCOMMEND}(Iter+1)}\right)<10^{-6}$\\\hline
 \end{tabular}
 }
\label{Paramtable2}
\end{table}
\normalsize
%Since we do not dispose of the true endmembers and proportions for this data set, we compare the performances of the algorithms qualitatively by analyzing their respective results, and quantitatively by measuring the error of reconstructing the image from the endmember and abundance estimates using the mean square error metric
%\begin{equation}\label{MSE}
%    MSE\equiv\frac{1}{Nd}\|\mathbf{X}-\mathbf{\hat{X}}\|_{F}^{2}.
%\end{equation}
%In (\ref{MSE}), $\mathbf{X}$ is the true data, and $\mathbf{\hat{X}}$ is the reconstructed data using the endmember and abundance estimates. In each context, each abundance value is multiplied by the corresponding membership value. In (\ref{MSE}), $N$ is the number of data points, $d$ is the number of spectral bands, and $\|.\|_{F}$ stands for the Frobenius norm.
\\Figures \ref{CDSUPCMDClustersPaviaU}(\subref{CDSUClustersPaviaU}) and (\subref{PCMDClustersPaviaU}) show the images of cluster assignment for both algorithms. Cluster assignments were based on the highest membership values.
\begin{figure}[!h]
\begin{subfigure}[b]{0.5\linewidth}
  \centering
\includegraphics[width=1\linewidth, height=1.3\linewidth]{CDSUClustersPavia.png}
\caption{}
  \label{CDSUClustersPaviaU}
\end{subfigure}
\begin{subfigure}[b]{0.5\linewidth}
   \centering
\includegraphics[width=1\linewidth, height=1.3\linewidth]{PCOMMENDClustersPavia.png}
\caption{}
  \label{PCMDClustersPaviaU}
\end{subfigure}
\caption{Cluster assignment images generated by (a) CDSU and (b) P-COMMEND on the Pavia University Data}
\label{CDSUPCMDClustersPaviaU}
\end{figure}
Table \ref{clustcompPCMD} shows the composition of the clusters generated by P-COMMEND, in percentage, taking into account the labeled points only.
\begin{table}
  \caption{Composition of the clusters generated by P-COMMEND, in percentage, taking into account the labeled points only}
  \centering
  \scalebox{0.6}{
  \begin{tabular}{|l|c|c|c|c|c|c|c|c|c|}
    \hline
    % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
     \backslashbox{Cluster}{Class} & Asphalt & Meadows & Gravel & Trees & Painted metal sheets & Bare soil & Bitumen & Self blocking bricks & Shadows \\\hline
    Cluster 1 & 16.01 & 22.78 & 3.19 & 35.36 & 0 & 7.14 & 0.19 & 15.30 & 0\\\hline
    Cluster 2 & 0.57 & 76.74 & 0.03 & 0.51 & 0 & 17.74 & 0.01 & 0.18 & 4.17\\\hline
    Cluster 3 & 40.89 & 0 & 14.58 & 0.03 & 10.66 & 4.71 & 10.38 & 18.66 & 0.06\\
    \hline
  \end{tabular}
  }
\label{clustcompPCMD}
\end{table}
We can see that cluster 1 is composed mostly of trees, meadows, asphalt and bricks. Cluster 2 is composed mostly of meadows, bare soil and shadows. And cluster 3 is composed mostly of asphalt, bricks, gravel, metal sheets and bitumen.
Table \ref{clustcompCDSU} shows the composition of the clusters generated by CDSU, in percentage, taking into account the labeled points only.
\begin{table}
  \caption{Composition of the clusters generated by CDSU, in percentage, taking into account the labeled points only}
  \centering
  \scalebox{0.6}{
  \begin{tabular}{|l|c|c|c|c|c|c|c|c|c|}
    \hline
    % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
   \backslashbox{Cluster}{Class}  & Asphalt & Meadows & Gravel & Trees & Painted metal sheets & Bare soil & Bitumen & Self blocking bricks & Shadows \\\hline
    Cluster 1 & 45.54 & 21.46 & 3.98 & 0.24 & 0.03 & 10.29 & 9.23 & 2.32 & 6.88\\\hline
    Cluster 2 & 0.05 & 73.08 & 0 & 14.71 & 0 & 12.14 & 0 & 0 & 0\\\hline
    Cluster 3 & 6.45 & 6.17 & 18.32 & 0.04 & 15.49 & 13.36 & 1.16 & 38.97 & 0\\
    \hline
  \end{tabular}
  }
\label{clustcompCDSU}
\end{table}
We can see that cluster 1 is composed mostly of asphalt, meadows, bare soil, bitumen and shadows. Cluster 2 is composed mostly of meadows, trees and bare soil. And cluster 3 is composed mostly of bricks, gravel, metal sheets and bare soil. This can also be seen in figures \ref{CDSUPCMDClustersPaviaUcomp}(\subref{CDSUClustersPaviaUcomp}) and (\subref{PCMDClustersPaviaUcomp}) where the same cluster compositions are represented visually.
\begin{figure}[!h]
\begin{subfigure}[b]{0.5\linewidth}
  \centering
\includegraphics[width=1\linewidth, height=1\linewidth]{CDSUClustersPaviacomp.png}
\caption{}
  \label{CDSUClustersPaviaUcomp}
\end{subfigure}
\begin{subfigure}[b]{0.5\linewidth}
   \centering
\includegraphics[width=1\linewidth, height=1\linewidth]{PCOMMENDClustersPaviacomp.png}
\caption{}
  \label{PCMDClustersPaviaUcomp}
\end{subfigure}
\caption{Composition, in percentage, of the clusters generated by (a) CDSU and (b) P-COMMEND on the Pavia University Data, taking into account the labeled points only.}
\label{CDSUPCMDClustersPaviaUcomp}
\end{figure}
Comparing the compositions of the clusters from both algorithms, we can see that some classes were divided into more than one cluster by both algorithms (meadows and bare soil). Other classes were divided into more than one cluster by P-COMMEND and less divided by CDSU (bricks and asphalt).

The proportion maps associated with the three endmembers for each of the three clusters found by P-COMMEND are shown in figures \ref{clus1paviapcmd}, \ref{clus2paviapcmd} and \ref{clus3paviapcmd}.
Since we do not have labels for the entire image, we analyze these proportion maps by comparing them with the RGB image in figure \ref{pavia}.
\\In cluster 1 (figure \ref{clus1paviapcmd}), the proportion map in figure \ref{clus1paviapcmd}(\subref{clus1em1pcmd}), corresponding to the first endmember, represents regions with high grass or trees. Similarly, we can see that the proportion map in figure \ref{clus1paviapcmd}(\subref{clus1em2pcmd}), corresponding to the second endmember in context 1, represents regions of shadow. The proportion map in figure \ref{clus1paviapcmd}(\subref{clus1em3pcmd}), corresponding to the third endmember in cluster 1, represents cement (parking lot).
\\In cluster 2 (figure \ref{clus2paviapcmd}), the proportion map in figure \ref{clus2paviapcmd}(\subref{clus2em1pcmd}), corresponding to the first endmember, represents regions of shadow. The proportion map in figure \ref{clus2paviapcmd}(\subref{clus2em2pcmd}), corresponding to the second endmember, represents regions with high grass or trees. Finally, the proportion map in figure \ref{clus2paviapcmd}(\subref{clus2em3pcmd}), corresponding to the third endmember, represents bricks (roofs).
\\In cluster 3 (figure \ref{clus3paviapcmd}), the proportion map in figure \ref{clus3paviapcmd}(\subref{clus3em1pcmd}), corresponding to the first endmember, represents cars. The proportion map in figure \ref{clus3paviapcmd}(\subref{clus3em2pcmd}), corresponding to the second endmember, represents asphalt (roads), bitumen (top of some roofs) and cement (top of some other roofs). Finally, the proportion map in figure \ref{clus3paviapcmd}(\subref{clus3em3pcmd}), corresponding to the third endmember, represents metal roofs.
\\We notice that the endmembers found by  P-COMMEND are repetitive in more than one cluster. For instance, endmembers corresponding to shadows, high grass and trees are found in cluster 1 and 2. Furthermore, the endmember for cement is found in clusters 1 and 3. Some endmembers represent non coherent elements, like combining asphalt and bitumen with cement in one endmember.
\newpage
\vfill
\begin{figure}[!htb]
\begin{subfigure}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=1\linewidth,height=1.3\linewidth]{PCMDClus1E1PaviaU.png}
  \caption{}
  \label{clus1em1pcmd}
\end{subfigure}
\begin{subfigure}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=1\linewidth,height=1.3\linewidth]{PCMDClus1E2PaviaU.png}
  \caption{}
  \label{clus1em2pcmd}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=0.5\linewidth,height=0.65\linewidth]{PCMDClus1E3PaviaU.png}
  \caption{}
  \label{clus1em3pcmd}
\end{subfigure}
\caption{Proportion maps for cluster 1 estimated by the P-COMMEND algorithm from the Pavia University hyperspectral data. Each pixel in the proportion maps was multiplied by the corresponding membership value for each context such that the endmembers with high proportion for each data point are highlighted.}
\label{clus1paviapcmd}
\end{figure}
\vfill
\clearpage
\newpage
\vfill
\begin{figure}[!htb]
\begin{subfigure}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=1\linewidth,height=1.3\linewidth]{PCMDClus2E1PaviaU.png}
  \caption{}
  \label{clus2em1pcmd}
\end{subfigure}
\begin{subfigure}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=1\linewidth,height=1.3\linewidth]{PCMDClus2E2PaviaU.png}
  \caption{}
  \label{clus2em2pcmd}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=0.5\linewidth,height=0.65\linewidth]{PCMDClus2E3PaviaU.png}
  \caption{}
  \label{clus2em3pcmd}
\end{subfigure}
\caption{Proportion maps for cluster 2 estimated by the P-COMMEND algorithm from the Pavia University hyperspectral data. Each pixel in the proportion maps was multiplied by the corresponding membership value for each context such that the endmembers with high proportion for each data point are highlighted.}
\label{clus2paviapcmd}
\end{figure}
\vfill
\clearpage
\newpage
\vfill
\begin{figure}[!htb]
\begin{subfigure}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=1\linewidth,height=1.3\linewidth]{PCMDClus3E1PaviaU.png}
  \caption{}
  \label{clus3em1pcmd}
\end{subfigure}
\begin{subfigure}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=1\linewidth,height=1.3\linewidth]{PCMDClus3E2PaviaU.png}
  \caption{}
  \label{clus3em2pcmd}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=0.5\linewidth,height=0.65\linewidth]{PCMDClus3E3PaviaU.png}
  \caption{}
  \label{clus3em3pcmd}
\end{subfigure}

\caption{Proportion maps for cluster 3 estimated by the P-COMMEND algorithm from the Pavia University hyperspectral data. Each pixel in the proportion maps was multiplied by the corresponding membership value for each context such that the endmembers with high proportion for each data point are highlighted.}
\label{clus3paviapcmd}
\end{figure}
\vfill
\clearpage
%The image reconstructed using the endmember and abundance estimates of P-COMMEND is illustrated in figure \ref{paviareconspcmd}.
%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.45\linewidth, height=0.65\linewidth]{Pavia305170reconstructedpcmd.png}
%\caption{Reconstructed image of the Pavia University data set from the endmember and abundance estimates of P-COMMEND (using bands 56, 29 and 12 to form R, G and B channels to create the color image)}
%\label{paviareconspcmd}
%\end{figure}

The proportion maps associated with the three endmembers for each of the three contexts (clusters) found by CDSU are shown in figures \ref{clus1paviacdsu}, \ref{clus2paviacdsu} and \ref{clus3paviacdsu}.
Since we do not have labels for the entire image, we analyze these proportion maps by comparing them with the RGB image in figure \ref{pavia}.
\\In context 1 (figure \ref{clus1paviacdsu}), the proportion map in figure \ref{clus1paviacdsu}(\subref{clus1em1cdsu}), corresponding to the first endmember, represents asphalt (roads) and bitumen (top of some roofs). Similarly, we can see that the proportion map in figure \ref{clus1paviacdsu}(\subref{clus1em2cdsu}), corresponding to the second endmember in context 1, represents shadows. The proportion map in figure \ref{clus1paviacdsu}(\subref{clus1em3cdsu}), corresponding to the third endmember in context 1, represents uneven bare soil.
\\In context 2 (figure \ref{clus2paviacdsu}), the proportion map in figure \ref{clus2paviacdsu}(\subref{clus2em1cdsu}), corresponding to the first endmember, represents regions with high grass or trees. The proportion map in figure \ref{clus2paviacdsu}(\subref{clus2em2cdsu}), corresponding to the second endmember, represents even bare soil. Finally, the proportion map in figure \ref{clus2paviacdsu}(\subref{clus2em3cdsu}), corresponding to the third endmember, represents regions with low grass.
\\In context 3 (figure \ref{clus3paviacdsu}), the proportion map in figure \ref{clus3paviacdsu}(\subref{clus3em1cdsu}), corresponding to the first endmember, represents cars. The proportion map in figure \ref{clus3paviacdsu}(\subref{clus3em2cdsu}), corresponding to the second endmember, represents metal roofs. Finally, the proportion map in figure \ref{clus3paviacdsu}(\subref{clus3em3cdsu}), corresponding to the third endmember, represents cement (parking lots, sidewalks and roofs) and bricks (roofs).
\\We notice that the endmembers found by CDSU are not repetitive in the three contexts and that they represent coherent elements.
\newpage
\vfill
\begin{figure}[!htb]
\begin{subfigure}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=1\linewidth,height=1.3\linewidth]{CDSUClus1E1PaviaU.png}
  \caption{}
  \label{clus1em1cdsu}
\end{subfigure}
\begin{subfigure}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=1\linewidth,height=1.3\linewidth]{CDSUClus1E2PaviaU.png}
  \caption{}
  \label{clus1em2cdsu}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=0.5\linewidth,height=0.65\linewidth]{CDSUClus1E3PaviaU.png}
  \caption{}
  \label{clus1em3cdsu}
\end{subfigure}
\caption{Proportion maps for context 1 estimated by the CDSU algorithm from the Pavia University hyperspectral data. Each pixel in the proportion maps was multiplied by the corresponding membership value for each context such that the endmembers with high proportion for each data point are highlighted.}
\label{clus1paviacdsu}
\end{figure}
\vfill
\clearpage
\newpage
\vfill
\begin{figure}[!htb]
\begin{subfigure}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=1\linewidth,height=1.3\linewidth]{CDSUClus2E1PaviaU.png}
  \caption{}
  \label{clus2em1cdsu}
\end{subfigure}
\begin{subfigure}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=1\linewidth,height=1.3\linewidth]{CDSUClus2E2PaviaU.png}
  \caption{}
  \label{clus2em2cdsu}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=0.5\linewidth,height=0.65\linewidth]{CDSUClus2E3PaviaU.png}
  \caption{}
  \label{clus2em3cdsu}
\end{subfigure}
\caption{Proportion maps for context 2 estimated by the CDSU algorithm from the Pavia University hyperspectral data. Each pixel in the proportion maps was multiplied by the corresponding membership value for each context such that the endmembers with high proportion for each data point are highlighted.}
\label{clus2paviacdsu}

\end{figure}
\vfill
\clearpage
\newpage
\vfill
\begin{figure}[!htb]
\begin{subfigure}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=1\linewidth,height=1.3\linewidth]{CDSUClus3E1PaviaU.png}
  \caption{}
  \label{clus3em1cdsu}
\end{subfigure}
\begin{subfigure}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=1\linewidth,height=1.3\linewidth]{CDSUClus3E2PaviaU.png}
  \caption{}
  \label{clus3em2cdsu}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=0.5\linewidth,height=0.65\linewidth]{CDSUClus3E3PaviaU.png}
  \caption{}
  \label{clus3em3cdsu}
\end{subfigure}

\caption{Proportion maps for context 3 estimated by the CDSU algorithm from the Pavia University hyperspectral data. Each pixel in the proportion maps was multiplied by the corresponding membership value for each context such that the endmembers with high proportion for each data point are highlighted.}
\label{clus3paviacdsu}
\end{figure}
\vfill
\clearpage
%The image reconstructed using the endmember and abundance estimates of CDSU is illustrated in figure \ref{paviareconscdsu}.
%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.45\linewidth, height=0.65\linewidth]{Pavia305170reconstructedCDSU.png}
%\caption{Reconstructed image of the Pavia University data set from the endmember and abundance estimates of CDSU (using bands 56, 29 and 12 to form R, G and B channels to create the color image)}
%\label{paviareconscdsu}
%\end{figure}
Figures \ref{EstimEPavia}(\subref{EstimEPaviaCDSU}) and (\subref{EstimEPaviaPCMD}) show the estimated endmembers by CDSU and P-COMMEND. Both algorithms agree on some endmembers like the ones corresponding to metal roofs, cars and high grass and trees, even though P-COMMEND generated a repetitive endmember for high grass and trees. P-COMMEND also generated a repetitive endmember for shadows.
\begin{figure}[!h]
\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{EstimatedEndmembersCDSU.png}
\caption{}
\label{EstimEPaviaCDSU}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
  \centering
  \includegraphics[width=1\linewidth, height=3.25in]{EstimatedEndmembersPCMD.png}
\caption{}
\label{EstimEPaviaPCMD}
\end{subfigure}
\caption{Estimated endmembers for the Pavia University hyperspectral data using (a) CDSU and (b) P-COMMEND.}
\label{EstimEPavia}
\end{figure}

In this section, we presented the results of the proposed CDSU algorithm on real hyperspectral data and compared them to those of P-COMMEND. Both methods did agree on some endmembers. However, while P-COMMEND resulted in some repetitive and non coherent endmembers, CDSU yielded coherent and non repetitive endmembers representing meaningful elements in the hyperspectral scene. This would have an impact on any further processing or analysis based on the estimated abundances or endmembers. These may include looking up the estimated endmembers in a spectral library to identify which elements they correspond to, or using the proportions as the pixels' features for a classification task.
\\The next chapter provides conclusions for this proposal and presents the proposed future work. 